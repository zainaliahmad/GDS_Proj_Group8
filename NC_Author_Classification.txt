// Create CO_AUTHOR_WITH Relationships
:auto
MATCH (a1:Author)-[:WROTE]->(p:Paper)<-[:WROTE]-(a2:Author)
WHERE a1.id < a2.id
CALL {
  WITH a1, a2
  MERGE (a1)-[:CO_AUTHOR_WITH]->(a2)
} IN TRANSACTIONS OF 1000 ROWS;

// Project GDS Graph for Louvain
CALL gds.graph.project(
  'authorCoAuthor',
  ['Author'],
  { CO_AUTHOR_WITH: { orientation: 'UNDIRECTED' } }
);

// Louvain Community Detection
CALL gds.louvain.write(
  'authorCoAuthor',
  { writeProperty: 'communityId' }
);

// Compute Dominant Topic for Each Author
MATCH (a:Author)
CALL {
  WITH a
  MATCH (a)-[:WROTE]->(:Paper)-[:HAS_TOPIC]->(t:Topic)
  WITH t.name AS topic, count(*) AS freq
  ORDER BY freq DESC
  LIMIT 1
  RETURN topic AS topTopic
}
SET a.author_domain = topTopic;

// Convert author_domain to Numeric domain_id
MATCH (a:Author)
WITH collect(DISTINCT a.author_domain) AS domains
UNWIND range(0, size(domains)-1) AS idx
WITH domains[idx] AS domain, idx AS domain_id
MATCH (a:Author {author_domain: domain})
SET a.domain_id = domain_id;

// Tag Authors for Training
MATCH (a:Author)
WHERE a.domain_id IS NOT NULL
SET a:TrainAuthor;

// Project TrainAuthor Graph
CALL gds.graph.project(
  'trainGraph',
  {
    TrainAuthor: {
      properties: ['domain_id']
    }
  },
  {
    CO_AUTHOR_WITH: {
      type:        'CO_AUTHOR_WITH',
      orientation: 'UNDIRECTED'
    }
  }
);

// USING RANDOM FOREST

// Define Pipeline
CALL gds.beta.pipeline.nodeClassification.create('authorNodeCls');

// Add Node Properties
CALL gds.beta.pipeline.nodeClassification.addNodeProperty(
  'authorNodeCls','fastRP',
  {
    mutateProperty:     'embed',
    embeddingDimension: 64,
    randomSeed:         58
  }
);

CALL gds.beta.pipeline.nodeClassification.addNodeProperty(
  'authorNodeCls','louvain',
  { mutateProperty: 'communityId' }
);

// Select Features
CALL gds.beta.pipeline.nodeClassification.selectFeatures(
  'authorNodeCls',
  ['embed','communityId','domain_id']
);

// Configure Train/Test Split
CALL gds.beta.pipeline.nodeClassification.configureSplit(
  'authorNodeCls',
  {
    validationFolds: 4,
    testFraction:    0.25
  }
);

// Add Random Forest Model
CALL gds.beta.pipeline.nodeClassification.addRandomForest(
  'authorNodeCls',
  { numberOfDecisionTrees: 25 }
);

// Train the Pipeline
CALL gds.beta.pipeline.nodeClassification.train(
  'trainGraph',
  {
    pipeline:           'authorNodeCls',
    modelName:          'authorDomainRF',
    targetNodeLabels:   ['TrainAuthor'],
    targetProperty:     'domain_id',
    randomSeed:         58,
    threadCount:        4,
    metrics:            ['F1_WEIGHTED','ACCURACY','OUT_OF_BAG_ERROR']
  }
)
YIELD modelInfo, modelSelectionStats
RETURN
  modelInfo.bestParameters                            AS bestParams,
  modelInfo.metrics.ACCURACY.test                     AS testAccuracy,
  modelInfo.metrics.F1_WEIGHTED.test                  AS testF1,
  modelInfo.metrics.OUT_OF_BAG_ERROR.test             AS testOOB,
  [c IN modelSelectionStats.modelCandidates | c.metrics.ACCURACY.validation.avg] AS validationScores;

// Predict on Training Graph
CALL gds.beta.pipeline.nodeClassification.predict.stream(
  'trainGraph',
  {
    pipeline:                       'authorNodeCls',
    modelName:                      'authorDomainRF',
    targetNodeLabels:              ['TrainAuthor'],
    includePredictedProbabilities: true
  }
)
YIELD nodeId, predictedClass, predictedProbabilities
WITH
  gds.util.asNode(nodeId)                AS authorNode,
  predictedClass                         AS predictedDomainId,
  predictedProbabilities[predictedClass] AS confidence
RETURN
  authorNode.id            AS authorId,
  authorNode.domain_id     AS trueDomainId,
  predictedDomainId,
  floor(confidence*100)    AS confidencePct
ORDER BY confidencePct DESC
LIMIT 20;

// USING LOGISTIC REGRESSION

// Define a New Pipeline
CALL gds.beta.pipeline.nodeClassification.create('authorNodeClsLR');

// Add Node Properties
CALL gds.beta.pipeline.nodeClassification.addNodeProperty(
  'authorNodeClsLR', 'fastRP',
  {
    mutateProperty:     'embed',
    embeddingDimension: 64,
    randomSeed:         58
  }
);

CALL gds.beta.pipeline.nodeClassification.addNodeProperty(
  'authorNodeClsLR', 'louvain',
  {
    mutateProperty: 'communityId'
  }
);

// Select Features
CALL gds.beta.pipeline.nodeClassification.selectFeatures(
  'authorNodeClsLR',
  ['embed', 'communityId', 'domain_id']
);

// Configure Train/Test Split
CALL gds.beta.pipeline.nodeClassification.configureSplit(
  'authorNodeClsLR',
  {
    validationFolds: 4,
    testFraction:    0.25
  }
);

// Add Logistic Regression Model
CALL gds.beta.pipeline.nodeClassification.addLogisticRegression(
  'authorNodeClsLR',
  {
    penalty: {range: [0.01, 1.0]},
    learningRate: 0.05,
    maxEpochs: 100
  }
);

// Train the Pipeline
CALL gds.beta.pipeline.nodeClassification.train(
  'trainGraph',
  {
    pipeline:           'authorNodeClsLR',
    modelName:          'authorDomainLR',
    targetNodeLabels:   ['TrainAuthor'],
    targetProperty:     'domain_id',
    randomSeed:         58,
    threadCount:        4,
    metrics:            ['F1_WEIGHTED','ACCURACY']
  }
)
YIELD modelInfo, modelSelectionStats
RETURN
  modelInfo.bestParameters                            AS bestParams,
  modelInfo.metrics.ACCURACY.test                     AS testAccuracy,
  modelInfo.metrics.F1_WEIGHTED.test                  AS testF1,
  [c IN modelSelectionStats.modelCandidates | c.metrics.ACCURACY.validation.avg] AS validationScores;

// Predict with Trained Logistic Regression Model
CALL gds.beta.pipeline.nodeClassification.predict.stream(
  'trainGraph',
  {
    pipeline:                       'authorNodeClsLR',
    modelName:                      'authorDomainLR',
    targetNodeLabels:              ['TrainAuthor'],
    includePredictedProbabilities: true
  }
)
YIELD nodeId, predictedClass, predictedProbabilities
WITH
  gds.util.asNode(nodeId)                AS authorNode,
  predictedClass                         AS predictedDomainId,
  predictedProbabilities[predictedClass] AS confidence
RETURN
  authorNode.id          AS authorId,
  authorNode.domain_id   AS trueDomainId,
  predictedDomainId,
  floor(confidence * 100) AS confidencePct
ORDER BY confidencePct DESC
LIMIT 20;

