// Before starting data loading, edit the Graph DB settings to increase heap sizes for data loading.
// Change the following:
dbms.memory.heap.initial_size=2G
dbms.memory.heap.max_size=4G
dbms.memory.pagecache.size=2G


// CONSTRAINTS (Uniqueness)
CREATE CONSTRAINT author_id     IF NOT EXISTS FOR (a:Author)  REQUIRE a.id IS UNIQUE;
CREATE CONSTRAINT paper_id      IF NOT EXISTS FOR (p:Paper)   REQUIRE p.id IS UNIQUE;
CREATE CONSTRAINT journal_name  IF NOT EXISTS FOR (j:Journal) REQUIRE j.name IS UNIQUE;
CREATE CONSTRAINT topic_id      IF NOT EXISTS FOR (t:Topic)   REQUIRE t.id IS UNIQUE;

// INDEXES (for frequently queried properties)
CREATE INDEX author_name      IF NOT EXISTS FOR (a:Author)  ON (a.name);
CREATE INDEX paper_year       IF NOT EXISTS FOR (p:Paper)   ON (p.year);
CREATE INDEX topic_name       IF NOT EXISTS FOR (t:Topic)   ON (t.name);
CREATE INDEX journal_publisher IF NOT EXISTS FOR (j:Journal) ON (j.publisher);

// Run the following blocks one by one

// LOAD NODES

// Authors
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_author.csv' AS row
MERGE (a:Author {id: row.`Author ID`})
SET a.name = row.`Author Name`,
    a.url  = row.`Author URL`
} IN TRANSACTIONS OF 1000 ROWS;

// Papers
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_paper.csv' AS row
MERGE (p:Paper {id: row.`Paper ID`})
SET p.title          = row.`Paper Title`,
    p.doi            = row.`Paper DOI`,
    p.year           = CASE WHEN row.`Paper Year` <> '' THEN toInteger(row.`Paper Year`) ELSE NULL END,
    p.citationCount  = CASE WHEN row.`Paper Citation Count` <> '' THEN toInteger(row.`Paper Citation Count`) ELSE 0 END,
    p.journalDate    = row.`Journal Date`
} IN TRANSACTIONS OF 1000 ROWS;

// Journals
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_journal.csv' AS row
MERGE (j:Journal {name: row.`Journal Name`})
SET j.publisher = row.`Journal Publisher`
} IN TRANSACTIONS OF 1000 ROWS;

// Topics
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_topic.csv' AS row
MERGE (t:Topic {id: toInteger(row.`Topic ID`)})
SET t.name = row.`Topic Name`,
    t.url  = row.`Topic URL`
} IN TRANSACTIONS OF 1000 ROWS;

// LOAD RELATIONSHIPS

// (:Author)-[:WROTE]->(:Paper)
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_author_paper.csv' AS row
MATCH (a:Author {id: row.`Author ID`})
MATCH (p:Paper  {id: row.`Paper ID`})
MERGE (a)-[:WROTE]->(p)
} IN TRANSACTIONS OF 1000 ROWS;

// (:Paper)-[:PUBLISHED_IN]->(:Journal)
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_paper_journal.csv' AS row
MATCH (p:Paper   {id:   row.`Paper ID`})
MATCH (j:Journal {name: row.`Journal Name`})
MERGE (p)-[:PUBLISHED_IN]->(j)
} IN TRANSACTIONS OF 1000 ROWS;

// (:Paper)-[:CITES]->(:Paper)
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_paper_reference.csv' AS row
MATCH (p1:Paper {id: row.`Paper ID`})
MATCH (p2:Paper {id: row.`Referenced Paper ID`})
MERGE (p1)-[:CITES]->(p2)
} IN TRANSACTIONS OF 1000 ROWS;

// (:Paper)-[:HAS_TOPIC]->(:Topic)
:auto
CALL {
LOAD CSV WITH HEADERS FROM 'file:///clean_paper_topic.csv' AS row
MATCH (p:Paper {id: row.`Paper ID`})
MATCH (t:Topic {id: toInteger(row.`Topic ID`)})
MERGE (p)-[:HAS_TOPIC]->(t)
} IN TRANSACTIONS OF 1000 ROWS;
